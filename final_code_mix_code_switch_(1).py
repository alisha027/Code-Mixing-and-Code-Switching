# -*- coding: utf-8 -*-
"""final_code_mix_code_switch (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bcQsJ7PX6hGk1d2RmAjtaQSdhfRM1Axh
"""

!pip install langdetect             # used for language detection and for n-gram generation
import pandas as pd
import re                           # for text searching, text manipulation
from nltk.tokenize import word_tokenize
from langdetect import detect

file_path = '/content/cleaned_kokbook.csv'
df = pd.read_csv(file_path)

# Display the first few rows
df.head()                          # Rows-6832 and start col- 4 and final columns = 7

def clean_text(text):
    text = re.sub(r'\d+', '', text)        # Remove digits
    text = re.sub(r'[^\w\s]', '', text)    # Remove punctuation
    text = text.lower()                    # Convert to lowercase
    tokens = word_tokenize(text)           # Tokenize text
    return tokens

import nltk
nltk.download('punkt')          # used for nltk environment(Natural Language Toolkit) (pretrained tokenizer)

df['tokens'] = df['text'].apply(clean_text)   # Replace 'text column name' with the actual column name
df.head()

from nltk.util import ngrams        # used for examine sequences and detect patterns in code mixed and code switch

# Function to detect language and generate n-grams
def detect_language_and_ngrams(text, n=2):
    tokens = clean_text(text)
    language_tags = [(token, detect(token)) for token in tokens]     # Detect language for each token
    n_grams = list(ngrams(language_tags, n))                        # Generate n-grams
    return n_grams

# Apply function to the dataset
df['n_grams'] = df['text'].apply(lambda x: detect_language_and_ngrams(x, 2))  # For bigrams
df.head()

from matplotlib import pyplot as plt         # represent frequency of d/f text stream in dataset
import seaborn as sns                      #informative statstical representation
_df_0.groupby('text').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

# Function to check if there is a code switch
def check_code_switch(n_gram):
    languages = [lang for word, lang in n_gram]
    return len(set(languages)) > 1                # True if more than one language is detected

# Labeling code-switching sequences
df['code_switch'] = df['n_grams'].apply(lambda ngrams: any(check_code_switch(ngram) for ngram in ngrams))
print(df[['text', 'code_switch']].head())

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

#preprocessing and tokenization
def preprocess_text(text):
    if pd.isna(text):  # Check for NaN values
        return ''
    # Convert text to lowercase
    text = text.lower()
    # Remove punctuation and numbers
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    # Tokenize the text
    tokens = word_tokenize(text)
    # Remove stop words and perform lemmatization
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return ' '.join(tokens)

# Apply preprocessing to the 'text' column
df['processed_text'] = df['text'].apply(preprocess_text)
df.head()

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize the TF-IDF vectorizer
vectorizer = TfidfVectorizer()

# Fit and transform the processed text
X = vectorizer.fit_transform(df['processed_text'])

print("Shape of X:", X.shape)       # 5701 unique words and 6831 rows

from sklearn.preprocessing import LabelEncoder
import numpy as np
# Encode the labels
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(df['Label'])

print("Shape of y:", y.shape)
print("Unique classes in y:", np.unique(y))

from sklearn.model_selection import train_test_split

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training data shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Testing data shape: X_test={X_test.shape}, y_test={y_test.shape}")

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Initialize the SVM classifier
svm_classifier = SVC(kernel='linear')
svm_classifier.fit(X_train, y_train)

y_pred = svm_classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")

from sklearn.linear_model import LogisticRegression

# Initialize and train Logistic Regression
lr_classifier = LogisticRegression(max_iter=1000)
lr_classifier.fit(X_train, y_train)

# Predict and evaluate
y_pred = lr_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")

from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer
cv_scores = cross_val_score(SVC(kernel='linear'), X, y, cv=5, scoring='accuracy')
print(f"Cross-validated accuracy: {np.mean(cv_scores):.4f}")
c_scores = cross_val_score(SVC(kernel='linear'), X, y, cv=5, scoring='recall')
print(f"Cross-validated recall: {np.mean(c_scores):.4f}")
c_s = cross_val_score(SVC(kernel='linear'), X, y, cv=5, scoring='precision')
print(f"Cross-validated precision: {np.mean(c_s):.4f}")
f1_scorer = make_scorer(f1_score, average='weighted')  # Use 'macro' for multi-class without weighting
# Assuming X and y are your features and labels
cv_score = cross_val_score(SVC(kernel='linear'), X, y, cv=5, scoring=f1_scorer)  # correct
print(f"Cross-validated f1_Score: {np.mean(cv_score):.4f}")

from tensorflow.keras.preprocessing.text import Tokenizer            # for applying CNN
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

# Tokenization
tokenizer = Tokenizer(num_words=10000)  # Adjust num_words as needed
tokenizer.fit_on_texts(df['processed_text'])
sequences = tokenizer.texts_to_sequences(df['processed_text'])

# Padding
maxlen = 100  # Adjust maxlen as needed
X_padded = pad_sequences(sequences, maxlen=maxlen)

from sklearn.preprocessing import LabelEncoder

# Assuming df['label'] has categorical string labels
label_encoder = LabelEncoder()
df['label_encoded'] = label_encoder.fit_transform(df['Label'])

from tensorflow.keras.utils import to_categorical

# Convert encoded labels to categorical
y_categorical = to_categorical(df['label_encoded'])

print("Shape of X_padded:", X_padded.shape)
print("Shape of y_categorical:", y_categorical.shape)

def preprocess_text(text):
    if pd.isna(text):  # Handle NaN values
        return ''
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    return text

# Apply preprocessing to the 'text' column
df['processed_text'] = df['text'].apply(preprocess_text)

df.head()

tokenizer = Tokenizer(num_words=10000)         # Adjust num_words as needed
tokenizer.fit_on_texts(df['processed_text'])
sequences = tokenizer.texts_to_sequences(df['processed_text'])
maxlen = 100  # Adjust maxlen as needed
X_padded = pad_sequences(sequences, maxlen=maxlen)
label_encoder = LabelEncoder()
df['label_encoded'] = label_encoder.fit_transform(df['Label'])
y_categorical = to_categorical(df['label_encoded'])
print("Shape of X_padded:", X_padded.shape)
print("Shape of y_categorical:", y_categorical.shape)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense

model = Sequential()                 # CNN
model.add(Embedding(input_dim=10000, output_dim=128, input_length=maxlen))
model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))
model.add(MaxPooling1D(pool_size=4))
model.add(Flatten())
model.add(Dense(10, activation='relu'))  # Adjust the number of units
model.add(Dense(y_categorical.shape[1], activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_padded, y_categorical, epochs=6, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X_padded, y_categorical)
print("Test loss:", loss)
print("Test accuracy:", accuracy)

import matplotlib.pyplot as plt

# Data for each epoch
epochs = [1, 2, 3, 4, 5, 6]
accuracy = [0.9897, 0.9984, 0.9986, 0.9976, 0.9999, 1.0000]  # Training accuracy
val_accuracy = [1.0000, 1.0000, 1.0000, 1.0000, 0.9993, 0.9978]  # Validation accuracy
loss = [0.1069, 0.0896, 0.0186, 0.0106, 0.0057, 0.0004]  # Training loss
val_loss = [0.1027, 0.0002, 0.0027, 0.0023, 0.0023, 0.0036]  # Validation loss

# Plotting Accuracy and Loss
plt.figure(figsize=(10, 5))

# Subplot for accuracy
plt.subplot(1, 2, 1)
plt.plot(epochs, accuracy, label='Training Accuracy', marker='o')
plt.plot(epochs, val_accuracy, label='Validation Accuracy', marker='o')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Subplot for loss
plt.subplot(1, 2, 2)
plt.plot(epochs, loss, label='Training Loss', marker='o', color='red')
plt.plot(epochs, val_loss, label='Validation Loss', marker='o', color='orange')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Add a common title for both subplots
plt.suptitle('Result Visualization of CNN Model', fontsize=16)

# Display the plot
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

import matplotlib.pyplot as plt

# Data from the training output
epochs = list(range(1, 7))  # 6 epochs
train_accuracy = [0.9897, 0.9984, 0.9986, 0.9976, 0.9999, 1.0000]
train_loss = [0.1069, 0.1033, 0.0109, 0.0043, 0.0011, 3.5672e-04]

val_accuracy = [1.0000, 1.0000, 1.0000, 1.0000, 0.9993, 0.9978]
val_loss = [0.0270, 0.0102, 0.0027, 0.0023, 0.0023, 0.0036]

# Create the figure and axes
fig, ax1 = plt.subplots()

# Plotting accuracy
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Accuracy', color='blue')
ax1.plot(epochs, train_accuracy, label='Train Accuracy', color='blue', marker='o')
ax1.plot(epochs, val_accuracy, label='Validation Accuracy', color='cyan', marker='o')
ax1.tick_params(axis='y', labelcolor='blue')

# Creating a second y-axis for the loss
ax2 = ax1.twinx()
ax2.set_ylabel('Loss', color='red')
ax2.plot(epochs, train_loss, label='Train Loss', color='red', linestyle='--', marker='x')
ax2.plot(epochs, val_loss, label='Validation Loss', color='orange', linestyle='--', marker='x')
ax2.tick_params(axis='y', labelcolor='red')

# Adding legends and title
fig.tight_layout()
ax1.legend(loc='upper left', bbox_to_anchor=(1.05, 1))
ax2.legend(loc='upper left', bbox_to_anchor=(1.05, 0.7))
plt.title('Training and Validation Accuracy vs. Loss -- overall evolution of CNN Model')
plt.show()

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size
embedding_dim = 100  # You can adjust this
max_length = X_padded.shape[1]  # Length of padded sequences
num_classes = y_categorical.shape[1]  # Number of classes
model = Sequential([
    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),
    LSTM(units=128, return_sequences=True),
    LSTM(units=64),
    Dense(num_classes, activation='softmax')
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Summary of the model
model.summary()

# Split data into training and validation sets
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)

# Train the model
history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))

# Evaluate the model
loss, accuracy = model.evaluate(X_val, y_val)
print(f"Validation loss: {loss}")
print(f"Validation accuracy: {accuracy}")

import matplotlib.pyplot as plt

# Data for each epoch
epochs = [1, 2, 3, 4, 5, 6,7,8,9,10]
accuracy = [0.9523, 0.9984, 0.9986, 0.9976, 0.9985,0.9993,0.9986,0.9993,0.9989,0.9963]  # Training accuracy
val_accuracy = [0.9963, 0.9981, 0.9963, 1.0000, 0.9993, 0.9978,0.9963,0.9987,0.9963,0.9963]  # Validation accuracy
loss = [0.1103, 0.1029, 0.0129, 0.0063, 0.0129, 0.0114,0.0053,0.0038,0.0022,0.0219]  # Training loss
val_loss = [0.0255, 0.0241, 0.0243, 0.0241, 0.0259, 0.0238,0.0234,0.0212,0.0220,0.0206]  # Validation loss

# Plotting Accuracy and Loss
plt.figure(figsize=(10, 5))

# Subplot for accuracy
plt.subplot(1, 2, 1)
plt.plot(epochs, accuracy, label='Training Accuracy', marker='o')
plt.plot(epochs, val_accuracy, label='Validation Accuracy', marker='o')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Subplot for loss
plt.subplot(1, 2, 2)
plt.plot(epochs, loss, label='Training Loss', marker='o', color='red')
plt.plot(epochs, val_loss, label='Validation Loss', marker='o', color='orange')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Add a common title for both subplots
plt.suptitle('Result Visualization of LSTM Model', fontsize=16)

# Display the plot
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

import matplotlib.pyplot as plt

# Data from the training output
epochs = list(range(1, 11))  # 10 epochs
train_accuracy = [0.5387, 0.8160, 0.9689, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]
train_loss = [0.6679, 0.4553, 0.1005, 0.0080, 0.0010, 0.00022152, 0.00016287, 0.00013718, 0.00011723, 0.00010185]

val_accuracy = [0.6600, 0.9550, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]
val_loss = [0.5438, 0.1915, 0.0109, 0.0012, 0.00023297, 0.00016384, 0.00013556, 0.00011717, 0.00010444, 0.00009468]

# Create the figure and axes
fig, ax1 = plt.subplots()

# Plotting accuracy
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Accuracy', color='blue')
ax1.plot(epochs, train_accuracy, label='Train Accuracy', color='blue', marker='o')
ax1.plot(epochs, val_accuracy, label='Validation Accuracy', color='cyan', marker='o')
ax1.tick_params(axis='y', labelcolor='blue')

# Creating a second y-axis for the loss
ax2 = ax1.twinx()
ax2.set_ylabel('Loss', color='red')
ax2.plot(epochs, train_loss, label='Train Loss', color='red', linestyle='--', marker='x')
ax2.plot(epochs, val_loss, label='Validation Loss', color='orange', linestyle='--', marker='x')
ax2.tick_params(axis='y', labelcolor='red')

# Adding legends and title
fig.tight_layout()
ax1.legend(loc='upper left', bbox_to_anchor=(1.05, 1))
ax2.legend(loc='upper left', bbox_to_anchor=(1.05, 0.7))
plt.title('Training and Validation Accuracy vs. Loss -- overall evolution of LSTM Model')
plt.show()

